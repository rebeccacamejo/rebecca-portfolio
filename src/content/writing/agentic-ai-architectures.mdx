---
title: "My Journey Into Agentic AI"
description: "If youâ€™re building your own agentic AI:
Donâ€™t start with â€œcoolâ€ â€” start with â€œreliable.â€
Workflows are your friends. Agents are a privilege.
Choose frameworks you understand inside-out.
Always have a plan for when things go wrong."
pubDate: '2025-08-11'
---

## **My Journey Into Agentic AI**

Two weeks ago, I got handed one of those projects that makes you both excited and slightly terrified:

> We need an AI system that can talk to customers, solve problems, and follow strict rulesâ€¦ but also adapt in real time.

Basically, an **agentic AI** â€” something smarter than a fixed script, but safer than an AI free-for-all.

So I did what I do: I binged read every resource I could find.

- [LangChainâ€™s guide on agent frameworks](https://blog.langchain.com/how-to-think-about-agent-frameworks/)
- [Anthropicâ€™s post on building effective agents](https://www.anthropic.com/engineering/building-effective-agents?ref=blog.langchain.com)
- [LangGraphâ€™s agentic concepts](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)
- â€¦and a **monster spreadsheet** comparing all the major frameworks.

Hereâ€™s what stuck with me â€” and how itâ€™s shaping the architecture weâ€™re building.

---

### **Act 1: Agents vs. Workflows**

The first thing I learned is that not all â€œagentâ€ talk means the same thing.

- **Workflows** = Pre-written recipes.  
  Think: â€œStep 1, clean input. Step 2, call API. Step 3, send response.â€ Predictable. Repeatable. No surprises.

- **Agents** = Improvisers.  
  They decide the steps, choose tools, and adapt as they go. Amazing for complex tasksâ€¦ risky if you donâ€™t set boundaries.

ğŸ’¡ *Lesson learned* -- Start with workflows. Only upgrade to agents when you have a problem that actually needs flexibility.

---

### **Act 2: The Simplicity Trap**

When youâ€™re first building, itâ€™s tempting to make the system â€œas smart as possibleâ€ from day one.  
But Anthropicâ€™s advice was blunt:

> *Most problems donâ€™t need an agent.*

A single prompt or a small chain might be enough â€” and way easier to test. Complexity should be earned, not assumed.

---

### **Act 3: Reliability is the Boss Battle**

The *real* challenge isnâ€™t getting an agent to do something.  
Itâ€™s making sure it:

- Has the right context
- Uses the right tool (and passes the right parameters to it)
- Doesnâ€™t hallucinate
- Fails *gracefully* when things go wrong

That means: **control what goes into the model at every step**. If the inputs are messy, the outputs will be too.

---

### **Act 4: Frameworks â€” Friend or Foe?**

Frameworks like **LangGraph** are incredible because they:

- Handle orchestration, retries, memory
- Let you combine declarative graphs with imperative code
- Support multi-agent systems and human-in-the-loop flows

But abstraction can hide dangerous details. You still need to know whatâ€™s happening under the hood.  

That's why I dove head first into CrewAI, LangGraph, Motia, MCP, etc. â€” to understand what is really going on from just one LLM call to chaining to routing to a ton of other patterns out there.

---

### **Act 5: Patterns Iâ€™m Keeping in My Toolbox**

- **Routing**: Send requests to the right â€œspecialistâ€ agent.
- **ReAct loops**: Reason â†’ Act â†’ Reason again.
- **Reflection**: Let the agent review its own work before sending it out.
- **Human-on-the-loop**: Autonomy most of the time, but with the ability for a person to jump in when it matters.

---

### **Act 6: My Hot Take**

In heavily regulated spaces, you can't have fully agentic architectures. We will always need humans on â€” and even in â€” the loop in some cases.

So, I think you should opt for a blend.

Hereâ€™s where all of this lands for us:

import AgenticArchitectureDiagram from "@components/misc/agentic-ai-architecture.astro";

<AgenticArchitectureDiagram />

### And the key design rules

- **Simplest thing first** â€” start deterministic, add autonomy later.  
- **Framework + visibility** â€” LangGraph for orchestration, but with logging for every prompt, tool call, and output.  
- **Safety nets everywhere** â€” human review, retries, fallback responses.  
- **Compliance built-in** â€” every step checked against our rules engine.  
